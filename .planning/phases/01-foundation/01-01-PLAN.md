---
phase: 01-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - Mflux_Comfy/Mflux_Core.py
  - Mflux_Comfy/utils/__init__.py
  - Mflux_Comfy/utils/tensor_utils.py
  - Mflux_Comfy/utils/memory_utils.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "mflux 0.15.5 imports without errors in Python environment"
    - "PIL Image converts to ComfyUI tensor [1,H,W,3] float32 in [0,1]"
    - "ComfyUI tensor converts to PIL Image without data loss"
    - "MLX cache clears after calling memory utility"
    - "Package imports work in Python 3.10+"
  artifacts:
    - path: "pyproject.toml"
      provides: "mflux 0.15.5 dependency"
      contains: "mflux==0.15.5"
    - path: "Mflux_Comfy/utils/tensor_utils.py"
      provides: "PIL<->ComfyUI tensor conversion"
      exports: ["pil_to_comfy_tensor", "comfy_tensor_to_pil"]
    - path: "Mflux_Comfy/utils/memory_utils.py"
      provides: "MLX memory management"
      exports: ["clear_mlx_memory", "get_memory_stats"]
    - path: "Mflux_Comfy/Mflux_Core.py"
      provides: "Updated imports for mflux 0.15.5"
      contains: "from mflux.models.common.config"
  key_links:
    - from: "Mflux_Comfy/Mflux_Core.py"
      to: "Mflux_Comfy/utils/tensor_utils.py"
      via: "import for tensor conversion"
      pattern: "from .utils.tensor_utils import"
    - from: "Mflux_Comfy/Mflux_Core.py"
      to: "Mflux_Comfy/utils/memory_utils.py"
      via: "import for memory clearing"
      pattern: "from .utils.memory_utils import"
---

<objective>
Update mflux dependency from 0.13.1 to 0.15.5 and extract reusable tensor/memory utilities.

Purpose: This foundation enables Phase 2 (Z-Image Turbo) and Phase 3 (SeedVR2) by ensuring the mflux library works correctly and providing clean utility functions for tensor conversion and memory management.

Output: Updated pyproject.toml, new utils module with tensor_utils.py and memory_utils.py, and Mflux_Core.py using the new utilities.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-RESEARCH.md
@pyproject.toml
@Mflux_Comfy/Mflux_Core.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update mflux dependency and fix import paths</name>
  <files>
    - pyproject.toml
    - Mflux_Comfy/Mflux_Core.py
  </files>
  <action>
1. Update pyproject.toml:
   - Change `mflux==0.13.1` to `mflux==0.15.5`
   - Keep `huggingface_hub>=0.26.0` as-is

2. Update Mflux_Core.py imports for mflux 0.15.5 API:
   - The existing import `from mflux.models.common.config import ModelConfig` should still work
   - Add import for Config: `from mflux.models.common.config.config import Config`
   - Remove the stub `class Config(dict)` since we now import the real one
   - Keep all existing model imports (Flux1, ZImageTurbo, etc.) - these paths haven't changed

3. In Mflux_Core.py, update the error message on line 48-49 from "mflux==0.13.1" to "mflux==0.15.5"

Note: The mflux 0.15.5 API is backward-compatible with 0.13.1 for ZImageTurbo usage. The main import path changes are documented in the RESEARCH.md.
  </action>
  <verify>
Run: `cd /Users/darrindemchuk/code/ai_images/mflux-comfyui && python -c "from mflux.models.common.config.config import Config; from mflux.models.z_image.variants.turbo.z_image_turbo import ZImageTurbo; print('Imports OK')"`
Expected: "Imports OK" printed without errors
  </verify>
  <done>
pyproject.toml shows mflux==0.15.5, and Python can import mflux Config and ZImageTurbo without errors.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create utils module with tensor and memory utilities</name>
  <files>
    - Mflux_Comfy/utils/__init__.py
    - Mflux_Comfy/utils/tensor_utils.py
    - Mflux_Comfy/utils/memory_utils.py
  </files>
  <action>
1. Create `Mflux_Comfy/utils/__init__.py`:
```python
"""Utility modules for mflux-comfyui."""
from .tensor_utils import pil_to_comfy_tensor, comfy_tensor_to_pil
from .memory_utils import clear_mlx_memory, get_memory_stats

__all__ = [
    "pil_to_comfy_tensor",
    "comfy_tensor_to_pil",
    "clear_mlx_memory",
    "get_memory_stats",
]
```

2. Create `Mflux_Comfy/utils/tensor_utils.py`:
```python
"""Tensor conversion utilities for ComfyUI integration.

ComfyUI IMAGE format: [B, H, W, C] float32 in range [0, 1]
PIL Image format: [H, W, C] uint8 in range [0, 255]
"""
import numpy as np
import torch
from PIL import Image


def pil_to_comfy_tensor(pil_image: Image.Image) -> torch.Tensor:
    """Convert PIL Image to ComfyUI IMAGE tensor.

    Args:
        pil_image: PIL Image in any mode (will be converted to RGB)

    Returns:
        torch.Tensor with shape [1, H, W, 3] and dtype float32, values in [0, 1]
    """
    # Ensure RGB mode
    rgb_image = pil_image.convert("RGB")

    # Convert to numpy and normalize to [0, 1]
    image_np = np.array(rgb_image).astype(np.float32) / 255.0

    # Convert to tensor and add batch dimension
    image_tensor = torch.from_numpy(image_np)
    if image_tensor.dim() == 3:
        image_tensor = image_tensor.unsqueeze(0)

    return image_tensor


def comfy_tensor_to_pil(tensor: torch.Tensor) -> Image.Image:
    """Convert ComfyUI IMAGE tensor to PIL Image.

    Args:
        tensor: torch.Tensor with shape [B, H, W, C] or [H, W, C],
                float32 in range [0, 1]

    Returns:
        PIL.Image.Image in RGB mode (first image if batch > 1)
    """
    # Handle batch dimension
    if tensor.dim() == 4:
        tensor = tensor[0]  # Take first in batch

    # Move to CPU, convert to numpy
    image_np = tensor.cpu().numpy()

    # Clamp and convert to uint8
    image_np = np.clip(image_np * 255.0, 0, 255).astype(np.uint8)

    return Image.fromarray(image_np)
```

3. Create `Mflux_Comfy/utils/memory_utils.py`:
```python
"""MLX memory management utilities.

Provides functions to clear GPU cache and monitor memory usage.
Safe to import even when MLX is not available (returns no-ops).
"""
import gc
import os

# Conditional MLX import (same pattern as Mflux_Core.py)
_skip_mlx_import = os.environ.get("MFLUX_COMFY_DISABLE_MLX_IMPORT") == "1"

try:
    if _skip_mlx_import:
        raise ImportError("Skipping MLX import via env var")
    import mlx.core as mx
    _MLX_AVAILABLE = True
except ImportError:
    mx = None
    _MLX_AVAILABLE = False


def clear_mlx_memory(cache_limit_bytes: int = 1_000_000_000) -> None:
    """Clear MLX cache and free memory.

    Call this after each generation to prevent OOM on subsequent runs.

    Args:
        cache_limit_bytes: Maximum cache size (default 1GB)
    """
    gc.collect()
    if _MLX_AVAILABLE and mx is not None:
        mx.set_cache_limit(cache_limit_bytes)
        mx.clear_cache()


def get_memory_stats() -> dict:
    """Get current MLX memory statistics.

    Returns:
        Dict with active_memory, peak_memory, cache_memory in bytes.
        Returns zeros if MLX is not available.
    """
    if not _MLX_AVAILABLE or mx is None:
        return {
            "active_memory": 0,
            "peak_memory": 0,
            "cache_memory": 0,
            "mlx_available": False,
        }

    return {
        "active_memory": mx.get_active_memory(),
        "peak_memory": mx.get_peak_memory(),
        "cache_memory": mx.get_cache_memory(),
        "mlx_available": True,
    }


def reset_memory_tracking() -> None:
    """Reset peak memory counter for fresh measurement."""
    if _MLX_AVAILABLE and mx is not None:
        mx.reset_peak_memory()
```
  </action>
  <verify>
Run: `cd /Users/darrindemchuk/code/ai_images/mflux-comfyui && python -c "from Mflux_Comfy.utils import pil_to_comfy_tensor, comfy_tensor_to_pil, clear_mlx_memory, get_memory_stats; print('Utils import OK')"`
Expected: "Utils import OK" printed without errors
  </verify>
  <done>
New utils/ directory exists with __init__.py, tensor_utils.py, and memory_utils.py. All four exported functions can be imported.
  </done>
</task>

<task type="auto">
  <name>Task 3: Integrate utils into Mflux_Core and verify full chain</name>
  <files>
    - Mflux_Comfy/Mflux_Core.py
  </files>
  <action>
1. Add imports at top of Mflux_Core.py (after existing imports, around line 11):
```python
from .utils.tensor_utils import pil_to_comfy_tensor
from .utils.memory_utils import clear_mlx_memory
```

2. Replace the inline tensor conversion in `generate_image()` function (lines 333-338):

BEFORE (current code):
```python
image_np = np.array(pil_image).astype(np.float32) / 255.0
image_tensor = torch.from_numpy(image_np)

if image_tensor.dim() == 3:
    image_tensor = image_tensor.unsqueeze(0)

return (image_tensor,)
```

AFTER (using utility):
```python
image_tensor = pil_to_comfy_tensor(pil_image)
return (image_tensor,)
```

3. In the `finally` block of generate_image() (around line 326), add memory clearing after gc.collect():

BEFORE:
```python
if low_ram:
    print("[MFlux-ComfyUI] Low RAM mode: Clearing model cache to free resources and reset state.")
    model_cache.clear()
    gc.collect()
```

AFTER:
```python
if low_ram:
    print("[MFlux-ComfyUI] Low RAM mode: Clearing model cache to free resources and reset state.")
    model_cache.clear()
    gc.collect()
    clear_mlx_memory()
```

4. Add memory clearing at end of generate_image() before return (always, not just low_ram mode):
```python
# Always clear MLX cache after generation to prevent memory accumulation
clear_mlx_memory()

return (image_tensor,)
```
  </action>
  <verify>
Run full verification script:
```bash
cd /Users/darrindemchuk/code/ai_images/mflux-comfyui && python -c "
import sys
print('1. Testing mflux imports...')
from mflux.models.common.config.config import Config
from mflux.models.z_image.variants.turbo.z_image_turbo import ZImageTurbo
print('   mflux imports: OK')

print('2. Testing utils imports...')
from Mflux_Comfy.utils import pil_to_comfy_tensor, comfy_tensor_to_pil, clear_mlx_memory, get_memory_stats
print('   utils imports: OK')

print('3. Testing tensor conversion round-trip...')
from PIL import Image
import numpy as np
import torch

# Create test image
test_pil = Image.new('RGB', (64, 64), color=(128, 64, 192))

# PIL -> ComfyUI tensor
tensor = pil_to_comfy_tensor(test_pil)
assert tensor.shape == torch.Size([1, 64, 64, 3]), f'Wrong shape: {tensor.shape}'
assert tensor.dtype == torch.float32, f'Wrong dtype: {tensor.dtype}'
assert 0.0 <= tensor.min() <= tensor.max() <= 1.0, f'Wrong range: [{tensor.min()}, {tensor.max()}]'
print(f'   PIL->tensor: shape={tensor.shape}, dtype={tensor.dtype}, range=[{tensor.min():.2f}, {tensor.max():.2f}]')

# ComfyUI tensor -> PIL
result_pil = comfy_tensor_to_pil(tensor)
assert result_pil.mode == 'RGB', f'Wrong mode: {result_pil.mode}'
assert result_pil.size == (64, 64), f'Wrong size: {result_pil.size}'
print(f'   tensor->PIL: mode={result_pil.mode}, size={result_pil.size}')

# Verify no data loss (within rounding tolerance)
original_pixel = test_pil.getpixel((0, 0))
result_pixel = result_pil.getpixel((0, 0))
assert all(abs(o - r) <= 1 for o, r in zip(original_pixel, result_pixel)), f'Data loss: {original_pixel} vs {result_pixel}'
print(f'   Round-trip pixel: original={original_pixel}, result={result_pixel}')

print('4. Testing memory utilities...')
stats = get_memory_stats()
print(f'   Memory stats: {stats}')
clear_mlx_memory()
print('   clear_mlx_memory: OK')

print('5. Testing Mflux_Core import...')
# This will test the updated imports work
from Mflux_Comfy import Mflux_Core
print('   Mflux_Core import: OK')

print()
print('ALL TESTS PASSED')
"
```
Expected: "ALL TESTS PASSED" at the end
  </verify>
  <done>
- Mflux_Core.py uses pil_to_comfy_tensor for output conversion
- Mflux_Core.py uses clear_mlx_memory after generation
- Full test script passes showing tensor round-trip works without data loss
- Package imports work correctly
  </done>
</task>

</tasks>

<verification>
Phase 1 success criteria checklist:

1. [ ] mflux 0.15.5 installs and imports without errors
   - Verify: `pip show mflux` shows version 0.15.5
   - Verify: `python -c "import mflux"` succeeds

2. [ ] PIL Image converts to ComfyUI tensor with correct shape [1, H, W, 3] and range [0, 1]
   - Verify: Test in Task 3 verification script

3. [ ] ComfyUI tensor converts back to PIL Image without data loss
   - Verify: Test in Task 3 verification script (pixel comparison)

4. [ ] MLX cache clears successfully after calling memory utility
   - Verify: `clear_mlx_memory()` call completes without error

5. [ ] Package imports without errors in Python 3.10+
   - Verify: `python -c "from Mflux_Comfy import Mflux_Core"` succeeds
</verification>

<success_criteria>
- pyproject.toml specifies mflux==0.15.5
- Mflux_Comfy/utils/ directory exists with tensor_utils.py and memory_utils.py
- Mflux_Core.py imports and uses the new utility functions
- Full verification script passes with "ALL TESTS PASSED"
- No import errors when loading the package
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-01-SUMMARY.md`
</output>
